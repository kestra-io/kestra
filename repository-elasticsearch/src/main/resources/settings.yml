index:
  analysis:
    analyzer:
      prefix:
        type: custom
        tokenizer: standard
        filter:
          - word_delimiter
          - asciifolding
          - lowercase
          - prefix_ngrams
      search:
        type: custom
        tokenizer: standard
        filter:
          - word_delimiter
          - asciifolding
          - lowercase
      analyser:
        type: custom
        tokenizer: standard
        filter:
          - english_possessive_stemmer
          - lowercase
          - english_stop
          - english_stemmer
    filter:
      english_stop:
        type: stop
        stopwords: _english_
      english_stemmer:
        type: stemmer
        name: english
      word_delimiter:
        type: word_delimiter
        preserve_original: true
      english_possessive_stemmer:
        type: stemmer
        name: possessive_english
      remove_numbers:
        type: pattern_replace
        pattern: "([^\\p{L}]+)"
        replacement: ''
      prefix_ngrams:
        side: front
        max_gram: 30
        min_gram: 1
        type: edge_ngram
